{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class User:\n",
    "    def __init__(self, user_id, name, num_checkins, num_beers, num_friends, friends, num_badges, is_supporter, facebook, twitter, foursquare, location, profile_picture, profile_banner):\n",
    "        self.user_id = user_id\n",
    "        self.name = name\n",
    "        self.num_checkins = num_checkins\n",
    "        self.num_beers = num_beers\n",
    "        self.num_friends = num_friends\n",
    "        self.friends = friends\n",
    "        self.num_badges = num_badges\n",
    "        self.is_supporter = is_supporter\n",
    "        self.facebook = facebook\n",
    "        self.twitter = twitter\n",
    "        self.foursquare = foursquare\n",
    "        self.location = location\n",
    "        self.profile_picture = profile_picture\n",
    "        self.profile_banner = profile_banner\n",
    "    \n",
    "    def __repr__(self):\n",
    "        support_prefix = \"is a\" if self.is_supporter else \"not a\"\n",
    "        return f\"{self.name} ({self.user_id}), {self.num_beers} beers, {self.num_checkins} checkins, {self.num_friends} friends, {self.num_badges} badges, {support_prefix} supporter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CheckIn:\n",
    "    def __init__(self, checkin_id, user_id, beer_id, rating = None, location_id = None, comment = None, tagged_friends = [], cheers = 0):\n",
    "        self.checkin_id = checkin_id\n",
    "        self.user_id = user_id\n",
    "        self.beer_id = beer_id\n",
    "        self.rating = rating\n",
    "        self.location_id = location_id\n",
    "        self.comment = comment\n",
    "        self.tagged_friends = tagged_friends\n",
    "        self.cheers = cheers\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"({self.checkin_id}, {self.user_id}, {self.beer_id}, {self.rating}, {self.location_id}, {self.comment}, {self.tagged_friends}, {self.cheers})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Beer:\n",
    "    def __init__(self, beer_id, name, brewery_id, style, abv, ibu, avg_rating, total_ratings, total_checkins, unique_users):\n",
    "        self.beer_id = beer_id\n",
    "        self.name = name\n",
    "        self.brewery_id = brewery_id\n",
    "        self.style = style\n",
    "        self.abv = abv\n",
    "        self.ibu = ibu\n",
    "        self.avg_rating = avg_rating\n",
    "        self.total_ratings = total_ratings\n",
    "        self.total_checkins = total_checkins\n",
    "        self.unique_users = unique_users\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"({self.beer_id}, {self.name}, {self.brewery_id}, {self.style}, {self.abv} ABV, {self.ibu} IBU, {self.avg_rating}, {self.total_ratings}, {self.total_checkins}, {self.unique_users})\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapping helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_headers = { \n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:80.0) Gecko/20100101 Firefox/80.0\",\n",
    "            \"Accept\": \"*/*\",\n",
    "            \"Accept-Language\": \"en-US,en;q=0.5\",\n",
    "            \"X-Requested-With\": \"XMLHttpRequest\",\n",
    "            \"Pragma\": \"no-cache\",\n",
    "            \"Cache-Control\": \"no-cache\",\n",
    "        }\n",
    "\n",
    "def referer_headers(referer):\n",
    "    headers = default_headers.copy()\n",
    "    headers['referer'] = referer\n",
    "    return headers\n",
    "\n",
    "cookies = {'untappd_user_v3_e': '59884cc5903a2ad0d4a2707a8caf891d9ac17e0c016977b66432c1e7ae6b2d5667ed6a177cccf18861870eb1c0d6b333888d6d0c01ae69b45e5dcd0c5bb00d1edReLZMP%2Fi3XSY3q3FUNdC6FMVPkz3hUGk%2FFPBfVStfaamglZ0wJMZczAFofaAewWTdWi%2BCC260FZ1uGrzfRWGg%3D%3D'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_stats_from_div(div, user_id):\n",
    "    def find_stat(href):\n",
    "        return int(div.find(\"a\", {\"href\": href}).find(\"span\", {\"class\": \"stat\"}).text.replace(\",\", \"\"))\n",
    "    \n",
    "    num_checkins = find_stat(f\"/user/{user_id}\")\n",
    "    num_beers = find_stat(f\"/user/{user_id}/beers\")\n",
    "    num_friends = find_stat(f\"/user/{user_id}/friends\")\n",
    "    num_badges = find_stat(f\"/user/{user_id}/badges\")\n",
    "    return num_checkins, num_beers, num_friends, num_badges\n",
    "    \n",
    "\n",
    "def find_details_from_div(div):\n",
    "    def find_socials(socials_div):\n",
    "        facebook, twitter, foursquare = None, None, None\n",
    "        socials_list = socials_div.findAll(\"a\")\n",
    "        for social in socials_list:\n",
    "            if social.text == \"Foursquare\":\n",
    "                foursquare = social[\"href\"]\n",
    "            if social.text == \"Facebook\":\n",
    "                facebook = social[\"href\"]\n",
    "            if social.text == \"Twitter\":\n",
    "                twitter = social[\"href\"]\n",
    "        return facebook, twitter, foursquare\n",
    "    \n",
    "    location_text = div.find(\"p\", {\"class\": \"location\"}).text\n",
    "    location = None if location_text == \"\" else location_text\n",
    "    \n",
    "    socials_div = div.find(\"div\", {\"class\": \"social\"})\n",
    "    facebook, twitter, foursquare = find_socials(socials_div)\n",
    "    return location, facebook, twitter, foursquare\n",
    "    \n",
    "\n",
    "def scrap_user_stats(user_id):    \n",
    "    user_url = f\"https://untappd.com/user/{user_id}\"\n",
    "    request = requests.get(user_url, headers=default_headers, cookies=cookies)\n",
    "    while request.status_code != 200:\n",
    "            print(f\"GET ERROR {request.status_code} for {user_id}'s stats\", end=\"\\r\")\n",
    "            sleep(2)\n",
    "            request = requests.get(user_url, headers=default_headers, cookies=cookies)\n",
    "            \n",
    "    soup = BeautifulSoup(request.text, 'html.parser')\n",
    "    \n",
    "    if soup.find(\"div\", {\"class\": \"private_user\"}) is not None:\n",
    "        return None\n",
    "    \n",
    "    name = soup.find(\"div\", {\"class\": \"info\"}).find(\"h1\").text.strip()\n",
    "    is_supporter = soup.find(\"div\", {\"class\": \"user-info\"}).find(\"span\", {\"class\": \"supporter\"}) is not None\n",
    "\n",
    "    stats_div = soup.find(\"div\", {\"class\": \"stats\"})\n",
    "    num_checkins, num_beers, num_friends, num_badges = find_stats_from_div(stats_div, user_id)\n",
    "    \n",
    "    details_div = soup.find(\"div\", {\"class\": \"user-details\"})\n",
    "    location, facebook, twitter, foursquare = find_details_from_div(details_div)\n",
    "    \n",
    "    profile_picture = soup.find(\"div\", {\"class\": \"avatar-holder\"}).find(\"img\")[\"src\"]\n",
    "    profile_banner = soup.find(\"div\", {\"class\": \"profile_header\"})[\"data-image-url\"]\n",
    "    \n",
    "    return User(user_id, name, num_checkins, num_beers, num_friends, None, num_badges, is_supporter, facebook, twitter, foursquare, location, profile_picture, profile_banner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_user_friends(user_id, number_of_friends=2147483647):\n",
    "    if number_of_friends == 0:\n",
    "        return []\n",
    "    \n",
    "    friends_url = f\"https://untappd.com/user/{user_id}/friends\"\n",
    "    request = requests.get(friends_url, headers=default_headers, cookies=cookies)\n",
    "    while request.status_code != 200:\n",
    "            print(f\"GET ERROR {request.status_code} for {user_id}'s friends\", end=\"\\r\")\n",
    "            sleep(2)\n",
    "            request = requests.get(user_url, headers=default_headers, cookies=cookies)\n",
    "    \n",
    "    soup = BeautifulSoup(request.text, 'html.parser')\n",
    "    friends_div = soup.find(\"div\", {\"class\": \"current\"}).findAll(\"span\", {\"class\": \"username\"})\n",
    "    friends = [span.getText() for span in friends_div]\n",
    "    \n",
    "    old_number_of_friends = 0\n",
    "    headers = referer_headers(f\"https://untappd.com/user/{user_id}/friends\")\n",
    "    while number_of_friends != len(friends) and old_number_of_friends != len(friends):\n",
    "        offset = len(friends)\n",
    "        more_friends_url_template = f\"https://untappd.com/friend/more_friends/{user_id}/{offset}?sort=\"\n",
    "            \n",
    "        request = requests.get(more_friends_url_template, headers=headers, cookies=cookies)\n",
    "        while request.status_code != 200:\n",
    "            print(f\"GET ERROR {request.status_code} for {user_id} with {offset}th friends\", end=\"\\r\")\n",
    "            if request.status_code == 429:\n",
    "                sleep(30)\n",
    "            request = requests.get(more_friends_url_template, headers=headers, cookies=cookies)\n",
    "            \n",
    "        soup = BeautifulSoup(request.text, 'html.parser')\n",
    "        old_number_of_friends = len(friends)\n",
    "        friends = friends + [a.text for a in soup.findAll(\"span\", {\"class\": \"username\"})]\n",
    "    return friends\n",
    "\n",
    "def scrap_user(user_id):\n",
    "    user_stats = scrap_user_stats(user_id)\n",
    "\n",
    "    if user_stats is None:\n",
    "        return None\n",
    "    \n",
    "    user_friends = scrap_user_friends(user_id, user_stats.num_friends)\n",
    "    user_stats.friends = user_friends\n",
    "    return user_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_checkin_from_html(checkin):\n",
    "    checkin_id = int(checkin[\"data-checkin-id\"])\n",
    "    checkin_div = checkin.find(\"p\", {\"class\": \"text\"})\n",
    "    user_id = checkin_div.find(\"a\", {\"class\": \"user\"})[\"href\"].split(\"/\")[-1]\n",
    "    checkin_description = checkin_div.contents\n",
    "    \n",
    "    beer_id = None\n",
    "    if ' is drinking a ' in checkin_description:\n",
    "        beer_id = int(checkin_description[checkin_description.index(' is drinking a ') + 1]['href'].split(\"/\")[-1])\n",
    "\n",
    "    location_id = None\n",
    "    if ' at ' in checkin_description:\n",
    "        location_id = int(checkin_description[checkin_description.index(' at ') + 1]['href'].split(\"/\")[-1])\n",
    "        \n",
    "    rating_div = checkin.find(\"div\", {\"class\": \"caps\"})\n",
    "    rating = None if rating_div is None else float(rating_div['data-rating'])\n",
    "\n",
    "    comment_div = checkin.find(\"p\", {\"class\": \"comment-text\"})\n",
    "    comment = None if comment_div is None else comment_div.text.strip()\n",
    "\n",
    "    tagged_friends_div = checkin.find(\"div\", {\"class\": \"tagged-friends\"})\n",
    "    tagged_friends = [] if tagged_friends_div is None else [a[\"href\"].split(\"/\")[-1] for a in tagged_friends_div.findAll(\"a\")]\n",
    "\n",
    "    cheers_div = checkin.find(\"div\", {\"class\": \"cheers\"})\n",
    "    cheers = 0 if cheers_div is None else int(cheers_div.find(\"span\", {\"class\": \"count\"}).find(\"span\").text)\n",
    "\n",
    "    return CheckIn(checkin_id, user_id, beer_id, rating, location_id, comment, tagged_friends, cheers)\n",
    "\n",
    "\n",
    "def scrap_user_checkins(user_id):\n",
    "    request_url = f\"https://untappd.com/user/{user_id}\"\n",
    "    request = requests.get(request_url, headers=default_headers, cookies=cookies)\n",
    "    checkins_div = BeautifulSoup(request.text, 'html.parser').select('div[id*=\"checkin_\"]')\n",
    "    \n",
    "    previous_len = 0\n",
    "    checkins = [parse_checkin_from_html(checkin) for checkin in checkins_div]\n",
    "\n",
    "    more_checkins_headers = referer_headers(f\"Referer: https://untappd.com/user/{user_id}\")\n",
    "    \n",
    "    while len(checkins) != previous_len and len(checkins) < 100:\n",
    "        last_checkin_id = checkins[-1].checkin_id\n",
    "        more_checkins_url = f\"https://untappd.com/profile/more_feed/{user_id}/{last_checkin_id}?v2=true\"\n",
    "        request = requests.get(more_checkins_url, headers=more_checkins_headers, cookies=cookies)\n",
    "        checkins_div = BeautifulSoup(request.text, 'html.parser').select('div[id*=\"checkin_\"]')\n",
    "        checkins += [parse_checkin_from_html(checkin) for checkin in checkins_div]\n",
    "        print(f\"Found {len(checkins)}\")\n",
    "    \n",
    "    return checkins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "beer_id = 96597\n",
    "beer_url = f\"https://untappd.com/b/a/{beer_id}\"\n",
    "request = requests.get(beer_url, headers=default_headers, cookies=cookies)\n",
    "soup = BeautifulSoup(request.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Gulden Draak 9000 Quadruple',\n",
       " 'BrouwerijVanSteenberge',\n",
       " 'Belgian Quadrupel',\n",
       " 10.5,\n",
       " 25,\n",
       " 3.88228,\n",
       " 105603)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_div = soup.find(\"div\", {\"class\": \"name\"})\n",
    "name = name_div.find(\"h1\").text\n",
    "brewery_id = name_div.find(\"a\")['href'].split(\"/\")[-1]\n",
    "style = name_div.find(\"p\", {\"class\":\"style\"}).text\n",
    "\n",
    "details_div = soup.find(\"div\", {\"class\": \"details\"})\n",
    "abv = float(details_div.find(\"p\", {\"class\": \"abv\"}).text.split(\"%\")[0])\n",
    "ibu_text = details_div.find(\"p\", {\"class\": \"ibu\"}).text.strip()\n",
    "ibu = None if ibu_text == \"No IBU\" else int(ibu_text.split(\" \")[0])\n",
    "avg_rating = float(details_div.find(\"div\", {\"class\": \"caps\"})[\"data-rating\"])\n",
    "total_ratings = int(details_div.find(\"p\", {\"class\": \"raters\"}).text.split(\" \")[0].replace(\",\", \"\"))\n",
    "\n",
    "\n",
    "name, brewery_id, style, abv, ibu, avg_rating, total_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crawling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_ids_to_df(user_ids):\n",
    "    df = pd.DataFrame(index=pd.Index(user_ids, name=\"user_id\"))\n",
    "    df[\"is_visited\"] = False\n",
    "    df[\"name\"] = None\n",
    "    df[\"checkins\"] = 0\n",
    "    df[\"beers\"] = 0\n",
    "    df[\"number_or_friends\"] = 0\n",
    "    df[\"friends\"] = None\n",
    "    df[\"badges\"] = 0\n",
    "    df[\"is_supporter\"] = False\n",
    "    \n",
    "    df.is_supporter = df.is_supporter.astype(dtype=np.bool, copy=False)\n",
    "    df.badges = df.badges.astype(dtype=np.int32, copy=False)\n",
    "    df.checkins = df.checkins.astype(dtype=np.int32, copy=False)\n",
    "    df.number_or_friends = df.number_or_friends.astype(dtype=np.int32, copy=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_users = [\"Dobby67\", \"Sourtats\", \"pasvaiste\", \"TombiLion\", \"errau\", \"timm3h\", \"Sheehan\", \"Jonnyhead\"]\n",
    "users_df = user_ids_to_df(start_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df = pd.read_pickle(\"untappd/crawled_users.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrapping Issegoz:\n",
      "GET ERROR 429 for Issegoz with 23000th friends\r"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "while users_df[~users_df.is_visited].shape[0] != 0 and i < 1000:\n",
    "    user_id = users_df[users_df.is_visited == False].index[0]\n",
    "    print(f\"Scrapping {user_id}:\")\n",
    "    \n",
    "    user_stats = scrap_user(user_id)\n",
    "    sleep(2)\n",
    "    \n",
    "    if user_stats is not None:\n",
    "        print(f\"    -> public profile ({user_stats.num_friends} friends)\")\n",
    "        unseen_users = [friend for friend in user_stats.friends if friend not in users_df.index]\n",
    "        print(f\"    -> with {len(unseen_users)} unseen ids\")\n",
    "        unseen_df = user_ids_to_df(unseen_users)\n",
    "        users_df = users_df.append(unseen_df)\n",
    "        users_df.loc[user_id] = (True, user_stats.name, user_stats.num_checkins, user_stats.num_beers, user_stats.num_friends, user_stats.friends, user_stats.num_badges, user_stats.is_supporter)\n",
    "    else:\n",
    "        print(\"    -> private profile\")\n",
    "        users_df.loc[user_id] = (True, None, 0, 0, 0, None, 0, False)\n",
    "        \n",
    "    print(f\"    -> {users_df.shape[0]} entries in total\")\n",
    "    users_df.to_pickle(\"untappd/crawled_users.pkl\")\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
